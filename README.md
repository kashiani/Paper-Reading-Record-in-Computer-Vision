#  Paper Reading Record in Computer Vision


## Table of Contents
- [Knowledge Distillation](#Knowledge-Distillation)
- [Domain Adaptation](#Domain-Adaptation)
- [Semi-Supervised Learning](#Semi-Supervised-Learning)
- [Semantic Segmentation](#Semantic-Segmentation)
- [Object Detection](#Object-Detection)
- [Visual Object Tracking](#Visual-Object-Tracking)
- [Data Augmentation](#Data-Augmentation)
- [Image-to-Image Translation](#Image-to-Image-Translation)
- [Multi-Domain Learning](#Multi-Domain-Learning)
- [Corruption Robustness](#Corruption-Robustness)
- [Adversarial Robustness](#Adversarial-Robustness)
- [Precious Papers](#Precious-Papers)
 

## Knowledge Distillation 

- [x]   Knowledge Distillation and Student-Teacher   Learning for Visual Intelligence: A Review and  New Outlooks
 (ArXiv 2020) [[Paper]](https://arxiv.org/abs/2004.05937)[Code] :star::star::star::star::star:

 >-   <font size="2">Knowledge distillation (KD) has been proposed to transfer information learned from one model to another</font>  
 >-   <font size="2">In this work, we focus on analyzing and categorizing   existing KD methods accompanied by various types of S-T   structures for model compression and knowledge transfer</font>  
 >-   <font size="2">Distillation from one teacher</font>  
 >-   <font size="2">Data-free distillation</font>  
 >-   <font size="2">Online distillation</font>  
 >-   <font size="2">Cross-modal distillation</font>  
 >-   <font size="2">Semi/self-supervised learning</font>  

 - [ ] Structured Knowledge Distillation for Dense Prediction (ArXiv 2020) [[Paper]](https://arxiv.org/abs/1903.04197)[[Code]](https://git.io/StructKD) :star::star::star:

- [ ] Knowledge Adaptation for Efficient Semantic Segmentation (CVPR  2019) [[Paper]](https://arxiv.org/abs/1903.04688)[Code] :star::star:

- [ ] Learning From Multiple Experts: Self-paced Knowledge Distillation for Long-tailed  Classification
 (ECCV 2020) [[Paper]](https://arxiv.org/abs/2001.01536)[Code] :star:


## Domain Adaptation

- [ ] A Review of Single-Source Deep Unsupervised Visual Domain Adaptation (ArXiv 2020) [[Paper]](https://arxiv.org/abs/2009.00155)[Code] :star::star::star::star:

- [ ] A Comprehensive Survey on Transfer Learning (ArXiv 2020) [[Paper]](https://arxiv.org/abs/1911.02685)[Code] :star::star::star::star:

- [ ]  Transfer Adaptation Learning: A Decade Survey (ArXiv 2020) [[Paper]](https://arxiv.org/abs/1903.04687)[Code] :star::star::star::star:

- [ ] Deep Visual Domain Adaptation: A Survey (Neurocomputing  2018) [[Paper]](https://arxiv.org/abs/1802.03601)[Code] :star::star:

- [ ] Multi-source Domain Adaptation in the Deep Learning Era: A Systematic Survey (ArXiv 2018) [[Paper]](https://arxiv.org/pdf/2002.12169.pdf)[Code] :star::star:

- [ ] DADA: Depth-Aware Domain Adaptation in Semantic Segmentation (ArXiv 2020) [[Paper]](https://arxiv.org/abs/1904.01886) [[Code]](https://github.com/valeoai/DADA)

- [ ] Multi-source Domain Adaptation for Semantic Segmentation (ArXiv 2020) [[Paper]](https://arxiv.org/abs/1910.12181) [[Code]](https://github.com/Luodian/MADAN):star:

- [ ] A Robust Learning Approach to Domain Adaptive Object Detection (ICCV 2019) [[Paper]](https://arxiv.org/pdf/1904.02361)[Code] 


## Semi-Supervised Learning
- [ ] Semi-Supervised Semantic Segmentation with Cross-Consistency Training (CVPR 2020) [[Paper]](https://arxiv.org/abs/2003.09005)[[Code]](https://github.com/yassouali/CCT) :star:

- [ ]  Semi-Supervised Semantic Segmentation via Dynamic Self-Training and Class-Balanced Curriculum  (ECCV 2020) [[Paper]](https://arxiv.org/abs/2004.08514)[[Code]](https://github.com/voldemortX/DST-CBC) :star:

- [ ]  Guided Collaborative Training for Pixel-wise Semi-Supervised Learning (ECCV 2020) [[Paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123580426.pdf)[[Code]](https://github.com/ZHKKKe/PixelSSL) :star:

- [ ]  FeatMatch: Feature-Based Augmentation for Semi-Supervised Learning (ECCV 2020) [[Paper]](https://arxiv.org/abs/2007.08505)[[Code]](https://sites.google.com/view/chiawen-kuo/home/featmatch) :star::star:



## Data Imbalance
- [ ] Prime Sample Attention in Object Detection (CVPR 2020) [[Paper]](https://arxiv.org/abs/1904.04821)[[Code]](https://github.com/open-mmlab/mmdetection) :star:


## Multi-Task Learning

- [ ] Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics (CVPR 2018) [[Paper]](https://arxiv.org/abs/1705.07115)[[Code]](https://feedforward.github.io/blog/multi-task-learning-using-uncertainty) 

 
## Semantic Segmentation

- [x] Benchmarking the Robustness of Semantic Segmentation Models (CVPR 2020) [[Paper]](https://arxiv.org/pdf/1908.05005.pdf) [Code]:star::star::star:

## Object Detection
- [ ] Boosting Weakly Supervised Object Detection with Progressive Knowledge Transfer (ECCV 2020) [[Paper]](https://arxiv.org/abs/2007.07986)[[Code]](https://github.com/mikuhatsune/wsod_transfer) 

- [ ] HoughNet: Integrating near and long-range evidence for bottom-up object detection (ECCV 2020) [[Paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123700409.pdf)[Code]


## Visual Object Tracking

- [ ] CLNet: A Compact Latent Network for Fast Adjusting Siamese Trackers (ECCV 2020) [[Paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650375.pdf)[[Code]](https://github.com/xingpingdong/CLNet-tracking) :star::heavy_check_mark: 
- [ ] Scale Equivariance Improves Siamese Tracking (ECCV 2020) [[Paper]](https://arxiv.org/pdf/2007.09115)[Code]

## Data Augmentation

- [ ] Adversarial Semantic Data Augmentation for  Human Pose Estimation (ECCV 2020) [[Paper]](https://arxiv.org/abs/2008.00697)[Code]
 
- [ ]  Unsupervised Data Augmentation for Consistency Training (NeurIPS 2020) [[Paper]](https://arxiv.org/abs/1904.12848)[[Code]](https://github.com/google-research/uda)
 
## Image-to-Image-Translation
- [ ]  Few-Shot Unsupervised Image-to-Image Translation (ICCV 2019) [[Paper]](https://arxiv.org/abs/1905.01723)[[Code]](https://nvlabs.github.io/FUNIT/)

- [ ] Unsupervised Domain Adaptation with Multiple Domain Discriminators and Adaptive Self-Training (ArXiv 2020) [[Paper]](https://arxiv.org/abs/2004.12724)[Code]

- [ ] DRIT++: Diverse Image-to-Image Translation via   Disentangled Representations (ArXiv 2020) [[Paper]](https://arxiv.org/abs/1905.01270)[Code]:star::star:

- [ ] EDIT: Exemplar-Domain Aware Image-to-Image Translation (ArXiv 2020) [[Paper]](https://arxiv.org/abs/1911.10520)[Code]:star:

- [ ]  GANHOPPER: Multi-Hop GAN for Unsupervised Image-to-Image Translation (ArXiv 2020) [[Paper]](https://arxiv.org/abs/2002.10102)[Code]:star:
 
- [ ]  Exemplar Guided Unsupervised Image-To-Image Translation With Semantic Consistency (ArXiv 2020) [[Paper]](https://arxiv.org/abs/1805.11145)[Code]:star:

- [ ]  Geometry-Consistent Generative Adversarial Networks for One-Sided Unsupervised Domain Mapping (ArXiv 2020) [[Paper]]()[Code]:star:

- [ ] Domain Bridge for Unpaired Image-to-Image Translation and Unsupervised Domain Adaptation (ArXiv 2020) [[Paper]]()[Code]:star:

- [ ]  On the Role of Receptive Field in Unsupervised Sim-to-Real Image Translation (ArXiv 2020) [[Paper]]()[Code]:star:

- [ ]  Multi-mapping Image-to-Image Translation via Learning Disentanglement (ArXiv 2020) [[Paper]]()[Code]:star:

- [ ]  INSTAGAN:   Instrance-Aware Image-To-ImageTranslation (ArXiv 2020) [[Paper]]()[Code]:star:
- [ ]  Towards Instance-level Image-to-Image Translation(ArXiv 2020) [[Paper]]()[Code]:star:

- [ ]  TuiGAN: Learning Versatile Image-to-Image Translation with Two Unpaired Images (ArXiv 2020) [[Paper]]()[Code]:star:


##  Multi-Domain Learning

- [ ] Budget-Aware Adapters for Multi-Domain Learning (ArXiv 2020) [[Paper]](https://arxiv.org/abs/1905.06242)[Code]

- [ ] Self-Supervised Representation Learning From Multi-Domain Data (ArXiv 2020) [[Paper]](https://openaccess.thecvf.com/content_ICCV_2019/papers/Feng_Self-Supervised_Representation_Learning_From_Multi-Domain_Data_ICCV_2019_paper.pdf)[Code]

- [ ] Efficient parametrization of multi-domain deep neural networks (ArXiv 2020) [[Paper]](https://arxiv.org/abs/1803.10082)[Code]

## Corruption Robustness
- [ ]  ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness (ICLR 2019) [[Paper]](https://arxiv.org/abs/1811.12231)[[Code]](https://github.com/rgeirhos/texture-vs-shape) :star::star::star::star:

- [ ]   Benchmarking Neural Network Robustness to Common Corruptions and Perturbations (ICLR 2019) [[Paper]](https://arxiv.org/abs/1907.07484)[[Code]](https://github.com/hendrycks/robustness) :star::star::star::star:

 - [ ]    Benchmarking Robustness in Object Detection: Autonomous Driving when Winter is Coming (NeurIPS 2019) [[Paper]](https://arxiv.org/abs/1903.12261)[[Code]](https://github.com/bethgelab/robust-detection-benchmark) :star::star::star::star:
 

## Adversarial Robustness

- [ ]  Adversarial Examples in Modern Machine Learning: A Review (ArXiv 2019) [[Paper]](https://arxiv.org/pdf/1911.05268.pdf)[Code]:star::star::star::star:
 
- [ ]  Opportunities and Challenges in Deep Learning Adversarial Robustness: A Survey (ArXiv 2020) [[Paper]](https://arxiv.org/abs/2007.00753)[Code]:star::star::star::star:

- [ ] Defending against adversarial examples using defense kernel network (BMVC 2019) [[Paper]](https://bmvc2019.org/wp-content/uploads/papers/0675-paper.pdf)[Code]

- [ ] Towards Evaluating the Robustness of Neural Networks (ArXiv 2017) [[Paper]](https://arxiv.org/abs/1608.04644)[Code]

- [ ]  A simple way to make neural networks robust against diverse image corruptions (EECV 2020) [[Paper]](https://arxiv.org/abs/2001.06057)[Code]:star::star:

## Precious Papers
- [ ]  Shortcut Learning in Deep Neural Networks (ArXiv 2020) [[Paper]](https://arxiv.org/pdf/2004.07780)[[Code]](https://github.com/rgeirhos/shortcut-perspective) :star::star::star::star::star:
- [ ]  Scale-Equivariant Steerable Networks (ArXiv 2020) [[Paper]](https://arxiv.org/abs/1910.11093)[[Code]](https://github.com/isosnovik/sesn) 
## Contact & Feedback

Feel free to contact me or pull request. 
- [E-mail](mailto:kashianihossein@gmail.com)
## License

[![CC0](http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://creativecommons.org/publicdomain/zero/1.0/)


This list is released into the public domain.
